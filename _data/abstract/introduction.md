---
layout: default
title: introduction
---
Listeners have the remarkable ability to combine acoustic information from speech with abstract linguistic knowledge, resulting in a structured representation of intended meaning. Recent work in psycho- and neurolinguistics has revealed signatures of this process in the brain: in the delta band (≤4Hz) – the timescale of occurrence of words and phrases in language – speech tracking is affected if the linguistic structure or content is manipulated (Blanco-Elorrieta et al., 2020; Molinaro & Lizarazu, 2018; Kaufeld et al., 2020). In the theta band (4-8 Hz), which corresponds to the timescale of syllables, speech tracking is affected by modifications of the acoustic signal (Blanco-Elorrieta et al., 2020; Etard & Reichenbach, 2019; Peelle, Gross & Davis, 2012; Doelling et al., 2014). Furthermore, lexical features also appear to be encoded in low-frequency neural responses (e.g., Weissbart et al., 2019; Brodbeck et al., 2018; Broderick et al., 2018). Yet, it is not clear how linguistic structure affects lexical encoding. Here we asked therefore how the neural response to words in the delta and theta bands changes, when spoken words appear in sentences or word lists.